{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(pd.__version__)\n",
    "### so that u dont have warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading restaurants data\n",
    "data_path = 'zomato.csv'\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= read_csv(data_path)\n",
    "\n",
    "# Results\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "url: contains the url of the restaurant in the zomato website;\n",
    "address: contains the address of the restaurant in Bengaluru;\n",
    "name: contains the name of the restaurant;\n",
    "online-order: whether online ordering is available in the restaurant or not;\n",
    "book-table: table book option available or not;\n",
    "rate: contains the overall rating of the restaurant out of 5;\n",
    "votes: contains total number of rating for the restaurant as of the above mentioned date;\n",
    "phone: contains the phone number of the restaurant;\n",
    "location: contains the neighborhood in which the restaurant is located;\n",
    "rest-type: restaurant type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  An overview from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting all NAN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_na=[feature for feature in df.columns if df[feature].isnull().sum()>0]\n",
    "feature_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% of missing values\n",
    "import numpy as np\n",
    "for feature in feature_na:\n",
    "    print('{} has {} % missing values'.format(feature,np.round(df[feature].isnull().sum()/len(df)*100,4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create arrays for features and missing values\n",
    "features = ['rate', 'phone', 'location', 'rest_type',\n",
    "            'dish_liked', 'cuisines', 'approx_cost(for two people)']\n",
    "missing_values = [15.0337, 2.3358, 0.0406, 0.4389, 54.2916, 0.087, 0.669]\n",
    "\n",
    "# Create horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "y_pos = np.arange(len(features))\n",
    "ax.barh(y_pos, missing_values, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(features)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Percentage of Missing Values')\n",
    "ax.set_title('Missing Values by Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Approx_cost column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['approx_cost(for two people)'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['approx_cost(for two people)'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['approx_cost(for two people)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### right now it has some NAN Values so it will be of float data-type,dats why very first we have to convert it into string then\n",
    "### we have to remove this comma\n",
    "df['approx_cost(for two people)'] = df['approx_cost(for two people)'].astype(str).apply(lambda x: x.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['approx_cost(for two people)']=df['approx_cost(for two people)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['approx_cost(for two people)'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing rate_num col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'][0].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    return x.split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### right now it has some NAN Values so it will be of float data-type,dats why very first weI have to convert it into string then\n",
    "### we have to split it & access \n",
    "df['rate']=df['rate'].astype(str).apply(split)\n",
    "### ''' df['rate'] = df['rate'].astype(str).apply(lambda x: x.split('/')[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].replace('NEW',0,inplace=True)\n",
    "df['rate'].replace('-',0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate']=df['rate'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many types of restaurants we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,12))\n",
    "df['rest_type'].value_counts().nlargest(20).plot.bar(color='red')\n",
    "\n",
    "### to provide styling to text on x-axis\n",
    "plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(x):\n",
    "    if x in ('Quick Bites', 'Casual Dining'):\n",
    "        return 'Quick Bites + Casual Dining'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Top_types']=df['rest_type'].apply(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "values=df['Top_types'].value_counts()\n",
    "labels=df['Top_types'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, values=values, names=labels,title='Restaurants Pie chart')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Almost 60 % of restaurants are of Casual Dining & Quick Bites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Most Voted Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=df.groupby('name').agg({'votes': 'sum','url': 'count','approx_cost(for two people)': 'mean','rate': 'mean'}).reset_index()\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.columns = ['name', 'total_votes', 'total_unities', 'avg_approx_cost', 'mean_rating']\n",
    "rest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest['votes_per_unity'] = rest['total_votes'] / rest['total_unities']\n",
    "rest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular=rest.sort_values(by='total_unities', ascending=False)\n",
    "popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Creating a figure for restaurants overview analysis\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(20,30))\n",
    "\n",
    "# Plot Pack 01 - Most popular restaurants (votes)\n",
    "\n",
    "# Annotations\n",
    "ax1.text(0.50, 0.30, int(popular['total_votes'].mean()), fontsize=45, ha='center')\n",
    "ax1.text(0.50, 0.12, 'is the average of votes', fontsize=12, ha='center')\n",
    "ax1.text(0.50, 0.00, 'received by restaurants', fontsize=12, ha='center')\n",
    "ax1.axis('off')\n",
    "\n",
    "sns.barplot(x='total_votes', y='name', data=popular.sort_values(by='total_votes', ascending=False)[0:5],ax=ax2, palette='plasma')\n",
    "ax2.set_title('Top 5 Most Voted Restaurants', size=12)\n",
    "\n",
    "sns.barplot(x='total_votes', y='name', data=popular.sort_values(by='total_votes', ascending=False).query('total_votes > 0').tail(),ax=ax3, palette='plasma_r')\n",
    "ax3.set_title('Top 5 Less Voted Restaurants\\n(with at least 1 vote)', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(20,30))\n",
    "# Annotations\n",
    "import numpy as np\n",
    "ax1.text(0.50, 0.30, np.round(popular['avg_approx_cost'].mean(), 2), fontsize=45, ha='center')\n",
    "ax1.text(0.50, 0.12, 'is mean approx cost', fontsize=12, ha='center')\n",
    "ax1.text(0.50, 0.00, 'for Bengaluru restaurants', fontsize=12, ha='center')\n",
    "ax1.axis('off')\n",
    "\n",
    "sns.barplot(x='avg_approx_cost', y='name', data=popular.sort_values(by='avg_approx_cost', ascending=False)[0:5],ax=ax2, palette='plasma')\n",
    "ax2.set_title('Top 5 Most Expensives Restaurants', size=12)\n",
    "\n",
    "sns.barplot(x='avg_approx_cost', y='name', data=popular.sort_values(by='avg_approx_cost', ascending=False).query('avg_approx_cost > 0').tail(),ax=ax3, palette='plasma_r')\n",
    "ax3.set_title('Top 5 Less Expensive Restaurants', size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many restaurants offer Book Table service? And how about Online Order service?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "x=df['book_table'].value_counts()\n",
    "labels=['not book','book']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace=go.Pie(labels=labels, values=x,\n",
    "               hoverinfo='label+percent', textinfo='percent', \n",
    "               textfont=dict(size=25),\n",
    "              pull=[0, 0, 0,0.2, 0]\n",
    "               )\n",
    "iplot([trace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "x=df['online_order'].value_counts()\n",
    "labels=['accepted','not accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, values=x, names=labels,title='Pie chart')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best budget Restaurants in any location\n",
    "    we will pass location and restaurant type as parameteres,function will return name of restaurants.Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_budget(location,restaurant):\n",
    "    budget=df[(df['approx_cost(for two people)']<=400) & (df['location']==location) & \n",
    "                     (df['rate']>4) & (df['rest_type']==restaurant)]\n",
    "    return(budget['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_budget('BTM',\"Quick Bites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geographical analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need Latitudes & longitudes for each of the place for geaographical Data analysis,so to fetch lat,lon of each place,use mapquest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations=pd.DataFrame({\"Name\":df['location'].unique()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['new_Name']='Bangalore '+locations['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.head"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapQuest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# MAPQUEST API\n",
    "API_KEY = 'FvWB34iwtjSNxakt3jRVLD2bQbrxQsUU'  # Replace with your API key\n",
    "BASE_URL = 'http://www.mapquestapi.com/geocoding/v1/address'\n",
    "\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for location in locations['Name']:\n",
    "    response = requests.get(\n",
    "        BASE_URL, params={'key': API_KEY, 'location': location})\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        lat = data['results'][0]['locations'][0]['latLng']['lat']\n",
    "        lng = data['results'][0]['locations'][0]['latLng']['lng']\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(lng)\n",
    "    else:\n",
    "        latitudes.append(None)\n",
    "        longitudes.append(None)\n",
    "\n",
    "print(latitudes)\n",
    "print(longitudes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['latitude']=latitudes\n",
    "locations['longitude']=longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.to_csv('zomato_locations.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_locations=pd.DataFrame(df['location'].value_counts().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_locations.columns=['Name','count']\n",
    "Rest_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now combine both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurant_locations=Rest_locations.merge(locations,on='Name',how=\"left\").dropna()\n",
    "Restaurant_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBaseMap(default_location=[12.97, 77.59], default_zoom_start=12):\n",
    "    base_map = folium.Map(location=default_location, zoom_start=default_zoom_start)\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "basemap=generateBaseMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap of Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HeatMap(Restaurant_locations[['latitude','longitude','count']].values.tolist(),zoom=20,radius=15).add_to(basemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is clear that restaurants tend to concentrate in central bangalore area.\n",
    "    The clutter of restaurants lowers are we move away from central.\n",
    "    So,potential restaurant entrepreneurs can refer this and find out good locations for their venture.\n",
    "    note heatmap is good when we have latitude,longitude or imporatnce of that particular place or count of that place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Predicting the Success of a Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['rated']=df['rate'].apply(assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_restaurants = df[df['rated'] == 0]\n",
    "train_val_restaurants = df.query('rated == 1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By now we've already splitted our original data into new_restaurants and train_val_restaurants using pandas DataFrames. Let's  keep the first one aside for now and let's work only with the training and validation set. The next step is to create our target variable to be used in this classification task.\n",
    "\n",
    "#### The main point here is to define a fair threshold for splitting the restaurants into good and bad ones. It would be a  really experimental decision and we must keep in mind that this approach is not the best one. Probably it would let margin for classification errors. Even so, let's try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_restaurants['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom threshold for splitting restaurants into good and bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a custom threshold for splitting restaurants into good and bad\n",
    "threshold = 3.75\n",
    "train_val_restaurants['target'] = train_val_restaurants['rate'].apply(lambda x: 1 if x >= threshold else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=train_val_restaurants['target'].value_counts()\n",
    "labels=x.index\n",
    "print(x)\n",
    "plt.pie(x,explode=[0.0,0.1],autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok, for our first trial it's fair. The meaning of all this is that we marked as good restaurants with a rate greater or equal to 3.75. Correct or not, let's continue to see what we can get from this.\n",
    "\n",
    "#### The next step is to prepare some features for training our classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After defining the target and splitting the data into train+val and test sets, let's define the features to be used on training. Here we will take a look at the raw data to select valuable features and apply some steps to create another ones.\n",
    "\n",
    "The initial set of selected features inclue:\n",
    "\n",
    "- online_order;\n",
    "- book_table;\n",
    "- location;\n",
    "- rest_type;\n",
    "- cuisines;\n",
    "- listed_in(type);\n",
    "- listed_in(city);\n",
    "- approx_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_restaurants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_val_restaurants['total_cuisines'] = train_val_restaurants['cuisines'].astype(str).apply(lambda x: len(x.split(',')))\n",
    "\n",
    "def count(x):\n",
    "    return len(x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### as it have some NAN value that's why, first I have to convert into str  &  then apply a function\n",
    "train_val_restaurants['total_cuisines']=train_val_restaurants['cuisines'].astype(str).apply(count)\n",
    "train_val_restaurants['multiple_types']=train_val_restaurants['rest_type'].astype(str).apply(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_restaurants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features=['online_order','book_table','location','rest_type','multiple_types','total_cuisines','listed_in(type)', 'listed_in(city)','approx_cost(for two people)','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_val_restaurants[imp_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='any',inplace=True) # inplace true to update the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features by data type\n",
    "cat_features= [col for col in data.columns if data[col].dtype == 'O']\n",
    "num_features= [col for col in data.columns if data[col].dtype != 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_features:\n",
    "    print('{} has total {} unique features'.format(feature, data[feature].nunique()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## on online_order,book_table & listed_in(type) we can apply Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But we will observe over here,we have many categories thus if we encode it using onne-hot encoding, it will consume more \n",
    "#### memory in our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['location','rest_type','listed_in(city)']\n",
    "for col in cols:\n",
    "    print('Total feature in {} are {}'.format(col,data[col].nunique()))\n",
    "    print(data[col].value_counts()/(len(data))*100)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent=data['location'].value_counts()/len(data)*100\n",
    "values=percent.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(values[values>0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### lets set Threshold value 0.4 ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=data['location'].value_counts()/len(data)*100\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.4\n",
    "imp=values[values>threshold]\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['location']=np.where(data['location'].isin(imp.index),data['location'],'other')\n",
    "\n",
    "##X_train['location']=X_train['location'].apply(lambda x:'other' if x not in imp.index else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['location'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values2=data['rest_type'].value_counts()/len(data)*100\n",
    "values2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rest_type'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(values2[values2>0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1.5\n",
    "imp2=values2[values2>1.5]\n",
    "imp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rest_type'].isin(imp2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rest_type']=np.where(data['rest_type'].isin(imp2.index),data['rest_type'],'other')\n",
    "##data['rest_type'].apply(lambda x: 'other' if x not in imp2.index else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rest_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### after apply feature reduction, we will observe less number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in cat_features:\n",
    "    print('{} has total {} unique features'.format(feature, data[feature].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_cat = data[cat_features]\n",
    "for col in cat_features:\n",
    "    col_encoded = pd.get_dummies(data_cat[col],prefix=col,drop_first=True) # drop_first=True because it removes the additional column encoding\n",
    "    data_cat=pd.concat([data_cat,col_encoded],axis=1)\n",
    "    data_cat.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.concat([data.loc[:,['multiple_types','total_cuisines','approx_cost(for two people)','target']],data_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X = data_final.drop('target', axis=1)\n",
    "y = data_final['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with some parameters.\n",
    "model = RandomForestClassifier(n_estimators=100, min_samples_leaf=10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data.\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Compute the error.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifier models\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression()))\n",
    "models.append(('Naive Bayes',GaussianNB()))\n",
    "models.append(('RandomForest', RandomForestClassifier()))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,model in models:\n",
    "    print(name)\n",
    "    print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions.\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Compute the error.\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(predictions, y_test))\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(accuracy_score(predictions,y_test))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "#Plot the confusion matrix\n",
    "#     # Make predictions on validation dataset\n",
    "\n",
    "# for name, model in models:\n",
    "#     print(name)\n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions.\n",
    "#     predictions = model.predict(X_test)\n",
    "\n",
    "#     # Compute the error.\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "#     cm = confusion_matrix(predictions, y_test)\n",
    "#     print(confusion_matrix(predictions, y_test))\n",
    "    \n",
    "#     # Plot the confusion matrix.\n",
    "#     fig, ax = plt.subplots(figsize=(6, 4))\n",
    "#     sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "\n",
    "#     # Add labels and title to the plot.\n",
    "#     ax.set_xlabel(\"Predicted labels\")\n",
    "#     ax.set_ylabel(\"True labels\")\n",
    "#     ax.set_title(name)\n",
    "\n",
    "#     # Show the plot.\n",
    "#     plt.show()\n",
    "#     from sklearn.metrics import accuracy_score\n",
    "#     print(accuracy_score(predictions,y_test))\n",
    "#     print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
